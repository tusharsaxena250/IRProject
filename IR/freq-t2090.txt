applic:2
absl:2
forc:2
if:1
equival:2
ani:2
help=helpwrap:8
keyflag:3
permiss:2
control:3
express:2
except:2
@:2
import:8
maxtrainsteps=tru:2
datasetsnumparallelbatch:3
see:4
multigpu:2
name=numparallelcal:2
condit:2
numer:2
tune:2
shortname=dt:2
shortname=gtmod:2
govern:2
dtype:6
usual:2
default=non:7
divid:2
defineperformancenumparallelcalls=tru:2
flagsvalidatorflagname=lossscal:2
shortname=int:2
recommend:2
softwar:2
help:2
devic:2
real:2
stabil:2
cast:2
obtain:2
limit:2
model:3
multiworkermirroredstrategi:2
divis:2
default=fp:2
dtype=tru:2
absoluteimport:2
intraop:3
getlossscal:2
unless:2
higher:2
epoch:2
name=lossscal:2
=:4
algorithm:3
tfdistributeexperimentalcollectivecommun:2
printfunct:2
requir:2
pool:2
flagsdefineinteg:9
string:2
cpu:4
help=helpwrapdefin:2
either:2
valid:3
disable=unusedvari:2
name=maxtrainstep:2
regist:3
shortname=mt:2
helpwrap:2
syntheticdata=tru:2
gpu:3
dtypemap:2
valu:2
name=allreducealg:2
set:7
of:1
worker:2
checklossscalelossscal:2
map:4
instead:2
flagsdefinestr:3
configproto:3
impli:2
whether:2
inter:2
globalstep:2
anyth:2
arg:2
name=usesyntheticdata:2
message=lossscalevalmsg:2
>:2
file:2
==============================================================================:2
input:3
specifi:7
train:5
behavior:2
copi:2
fake:2
nccl:2
tfgputhreadmod:4
officialutilsflagsconvent:2
stop:2
reserv:2
comput:3
help=helpwrapth:3
return:8
flag:13
name=intraopparallelismthread:2
help=helpwrapnumb:3
kind:2
flagsobjlossscal:3
mani:3
datasetsnumparallelbatches=fals:2
default=fals:2
mathemat:2
right:2
interop=tru:2
intra:2
tfdata:3
time:2
calcul:2
mode:2
default=multiprocessingcpucount:2
flagsdefineenum:2
tf:2
law:2
maximum:2
interop:3
amount:2
datasetsnumprivatethread:3
shortname=l:2
disable=gbadimportord:3
process:6
null:2
make:2
approxim:2
thi:10
intraop=tru:2
futur:4
to:1
threadpool:3
warranti:2
precis:2
shortname=synth:2
default:4
option:2
pylint:4
or:1
name=pergputhreadcount:2
fp:4
core:2
befor:3
handl:2
write:2
specif:6
allow:5
is:1
integ:2
httpwwwapacheorglicenseslicens:2
basi:3
ring:2
dtypemapflagsobjdtyp:3
name=interopparallelismthread:2
detail:3
variabl:3
mirroredstrategi:2
global:2
privat:4
onli:2
multiprocess:2
datasetsnumprivatethreads=fals:2
argument:2
batch:5
tfcontribdistributeallreducecrosstowerop:2
allreducealg=tru:2
singl:2
multipli:2
appli:2
avail:2
without:3
default=:4
determin:3
loss:8
gettfdtypeflagsobj:2
key:2
apach:2
tensorflow:7
complianc:2
data:6
a:1
gener:3
zero:3
lossscal:5
allreduc:2
list:2
trainepochs=:2
shortname=ara:2
us:2
mark:2
larger:2
may:4
intermedi:2
scale:7
tffloat:3
posit:2
learn:2
name=tfgputhreadmod:2
run:4
agre:2
trigger:2
languag:2
adjust:2
getlossscaleflagsobj:2
remov:2
shortname=intra:2
shortname=pgtc:2
numparallelcal:3
synthet:2
distribut:3
optim:3
enumvalues=dtypemapkey:2
true:2
syntheticdata:3
lossscalevalmsg:2
record:2
debug:2
name=datasetsnumparallelbatch:2
author:2
copyright:2
interopparallelismthread:2
it:1
reach:2
perform:5
flagsdefinebool:2
underflow:2
casebycas:2
use:14
op:3
avoid:2
parallel:5
version:2
datatyp:2
load:2
step:3
gpupriv:2
creat:8
corepi:2
per:2
tfgputhreadmode=fals:2
as:1
intraopparallelismthread:2
def:5
thread:7
maxtrainstep:3
allreducealg:3
dataset:4
dure:2
homogen:2
number:8
gradient:5
name=datasetsnumprivatethread:2
none:3
shortname=npc:2
name=dtyp:2
provid:2
licens:9
case:2
